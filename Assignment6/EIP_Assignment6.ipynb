{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EIP_Assignment6.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "asmWzCnnKol_",
        "colab_type": "code",
        "outputId": "98c40f28-f1e0-40ec-e47e-56c33b77c540",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Load Larger LSTM network and generate text\n",
        "import sys\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "import string\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM, Embedding\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIpMNetQQHmV",
        "colab_type": "code",
        "outputId": "78fa8ec2-ed28-4bc0-d951-80209158b01b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Mounting GDrive on Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRB5uCDBMohG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load ascii text and covert to lowercase\n",
        "filename = \"/content/gdrive/My Drive/wonderland.txt\"\n",
        "raw_text = open(filename).read()\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYt9rAW2S_fb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "remove = string.punctuation\n",
        "remove = remove.replace(\".\", \"\") # don't remove full stops\n",
        "pattern = r\"[{}]\".format(remove) # create the pattern\n",
        "\n",
        "raw_text_modified = re.sub(pattern, \"\", raw_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5-kiehxMo4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create mapping of unique chars to integers, and a reverse mapping\n",
        "chars = sorted(list(set(raw_text_modified)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLU5daKCMpSk",
        "colab_type": "code",
        "outputId": "5911b05d-e414-497a-ca9c-e8b96521f36d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# summarize the loaded data\n",
        "n_chars = len(raw_text_modified)\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Characters: \", n_chars)\n",
        "print (\"Total Vocab: \", n_vocab)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  154859\n",
            "Total Vocab:  38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g00E_1rvWAE9",
        "colab_type": "text"
      },
      "source": [
        "#Processing data - splitting by sentences, creating sequences and applying padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I0meF49_qST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def process_data(data):\n",
        "    #Split the data into sentences\n",
        "    corpus = data.splitlines()\n",
        "    #Convert data to sequence of tokens \n",
        "    input_sequences = []\n",
        "    for line in corpus:\n",
        "        for i in range(1, len(line)):\n",
        "            sequence = list(line[:i+1])\n",
        "            input_sequences.append([char_to_int[char] for char in sequence])\n",
        "    \n",
        "    max_sequence_len = max([len(x) for x in input_sequences])\n",
        "    padded_input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre')\n",
        "    \n",
        "    return padded_input_sequences, max_sequence_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg9kl--WAokP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, max_sequence_len = process_data(raw_text_modified)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYj9jReyVJLs",
        "colab_type": "text"
      },
      "source": [
        "#Preparing the Training data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9yNVOd9AvHW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataX = []\n",
        "dataY = []\n",
        "\n",
        "for i in range(len(X)):\n",
        "  dataX.append(X[i][:-1])\n",
        "  dataY.append(X[i][-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFBiVh1hBe7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_patterns = len(dataX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJ7baJ92BRhl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = np.reshape(dataX, (n_patterns, max_sequence_len-1, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytV7U1JwVPtI",
        "colab_type": "text"
      },
      "source": [
        "#Defining the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvoxZsVyM3BS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "0d1b0d9b-5280-49db-c1fc-f071ce487b44"
      },
      "source": [
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True,dropout=0.1))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(LSTM(256))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0727 13:16:19.565547 140279839074176 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0727 13:16:19.604320 140279839074176 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0727 13:16:19.616591 140279839074176 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0727 13:16:19.812847 140279839074176 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0727 13:16:19.827747 140279839074176 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZnCW6ykM3Uq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "28931b98-8edc-455d-b454-ccd467a96d48"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0727 13:16:29.954361 140279839074176 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0727 13:16:29.988256 140279839074176 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Adx8QHdNGDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the checkpoint\n",
        "filepath=\"/content/gdrive/My Drive/weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgX0INX7Vk8m",
        "colab_type": "text"
      },
      "source": [
        "#Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwc4xAYzMk3O",
        "colab_type": "code",
        "outputId": "21f3e2da-deea-4661-c1ec-92b48dfacc09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# fit the model\n",
        "model.fit(X, y, epochs=100, batch_size=256, callbacks=callbacks_list)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0727 13:16:42.831551 140279839074176 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "148335/148335 [==============================] - 126s 852us/step - loss: 2.7619\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.76188, saving model to /content/gdrive/My Drive/weights-improvement-01-2.7619-bigger.hdf5\n",
            "Epoch 2/100\n",
            "148335/148335 [==============================] - 121s 819us/step - loss: 2.4918\n",
            "\n",
            "Epoch 00002: loss improved from 2.76188 to 2.49179, saving model to /content/gdrive/My Drive/weights-improvement-02-2.4918-bigger.hdf5\n",
            "Epoch 3/100\n",
            "148335/148335 [==============================] - 121s 816us/step - loss: 2.2983\n",
            "\n",
            "Epoch 00003: loss improved from 2.49179 to 2.29832, saving model to /content/gdrive/My Drive/weights-improvement-03-2.2983-bigger.hdf5\n",
            "Epoch 4/100\n",
            "148335/148335 [==============================] - 120s 810us/step - loss: 2.1502\n",
            "\n",
            "Epoch 00004: loss improved from 2.29832 to 2.15020, saving model to /content/gdrive/My Drive/weights-improvement-04-2.1502-bigger.hdf5\n",
            "Epoch 5/100\n",
            "148335/148335 [==============================] - 120s 806us/step - loss: 2.0404\n",
            "\n",
            "Epoch 00005: loss improved from 2.15020 to 2.04041, saving model to /content/gdrive/My Drive/weights-improvement-05-2.0404-bigger.hdf5\n",
            "Epoch 6/100\n",
            "148335/148335 [==============================] - 120s 812us/step - loss: 1.9596\n",
            "\n",
            "Epoch 00006: loss improved from 2.04041 to 1.95958, saving model to /content/gdrive/My Drive/weights-improvement-06-1.9596-bigger.hdf5\n",
            "Epoch 7/100\n",
            "148335/148335 [==============================] - 119s 805us/step - loss: 1.8874\n",
            "\n",
            "Epoch 00007: loss improved from 1.95958 to 1.88744, saving model to /content/gdrive/My Drive/weights-improvement-07-1.8874-bigger.hdf5\n",
            "Epoch 8/100\n",
            "148335/148335 [==============================] - 120s 809us/step - loss: 1.8196\n",
            "\n",
            "Epoch 00008: loss improved from 1.88744 to 1.81956, saving model to /content/gdrive/My Drive/weights-improvement-08-1.8196-bigger.hdf5\n",
            "Epoch 9/100\n",
            "148335/148335 [==============================] - 121s 814us/step - loss: 1.7660\n",
            "\n",
            "Epoch 00009: loss improved from 1.81956 to 1.76603, saving model to /content/gdrive/My Drive/weights-improvement-09-1.7660-bigger.hdf5\n",
            "Epoch 10/100\n",
            "148335/148335 [==============================] - 120s 806us/step - loss: 1.7163\n",
            "\n",
            "Epoch 00010: loss improved from 1.76603 to 1.71629, saving model to /content/gdrive/My Drive/weights-improvement-10-1.7163-bigger.hdf5\n",
            "Epoch 11/100\n",
            "148335/148335 [==============================] - 120s 806us/step - loss: 1.6713\n",
            "\n",
            "Epoch 00011: loss improved from 1.71629 to 1.67132, saving model to /content/gdrive/My Drive/weights-improvement-11-1.6713-bigger.hdf5\n",
            "Epoch 12/100\n",
            "148335/148335 [==============================] - 120s 807us/step - loss: 1.6299\n",
            "\n",
            "Epoch 00012: loss improved from 1.67132 to 1.62988, saving model to /content/gdrive/My Drive/weights-improvement-12-1.6299-bigger.hdf5\n",
            "Epoch 13/100\n",
            "148335/148335 [==============================] - 119s 805us/step - loss: 1.5949\n",
            "\n",
            "Epoch 00013: loss improved from 1.62988 to 1.59493, saving model to /content/gdrive/My Drive/weights-improvement-13-1.5949-bigger.hdf5\n",
            "Epoch 14/100\n",
            "148335/148335 [==============================] - 119s 802us/step - loss: 1.5565\n",
            "\n",
            "Epoch 00014: loss improved from 1.59493 to 1.55651, saving model to /content/gdrive/My Drive/weights-improvement-14-1.5565-bigger.hdf5\n",
            "Epoch 15/100\n",
            "148335/148335 [==============================] - 119s 801us/step - loss: 1.5255\n",
            "\n",
            "Epoch 00015: loss improved from 1.55651 to 1.52549, saving model to /content/gdrive/My Drive/weights-improvement-15-1.5255-bigger.hdf5\n",
            "Epoch 16/100\n",
            "148335/148335 [==============================] - 119s 804us/step - loss: 1.4899\n",
            "\n",
            "Epoch 00016: loss improved from 1.52549 to 1.48992, saving model to /content/gdrive/My Drive/weights-improvement-16-1.4899-bigger.hdf5\n",
            "Epoch 17/100\n",
            "148335/148335 [==============================] - 122s 823us/step - loss: 1.4597\n",
            "\n",
            "Epoch 00017: loss improved from 1.48992 to 1.45966, saving model to /content/gdrive/My Drive/weights-improvement-17-1.4597-bigger.hdf5\n",
            "Epoch 18/100\n",
            "148335/148335 [==============================] - 123s 826us/step - loss: 1.4307\n",
            "\n",
            "Epoch 00018: loss improved from 1.45966 to 1.43070, saving model to /content/gdrive/My Drive/weights-improvement-18-1.4307-bigger.hdf5\n",
            "Epoch 19/100\n",
            "148335/148335 [==============================] - 123s 827us/step - loss: 1.4034\n",
            "\n",
            "Epoch 00019: loss improved from 1.43070 to 1.40336, saving model to /content/gdrive/My Drive/weights-improvement-19-1.4034-bigger.hdf5\n",
            "Epoch 20/100\n",
            "148335/148335 [==============================] - 123s 830us/step - loss: 1.3716\n",
            "\n",
            "Epoch 00020: loss improved from 1.40336 to 1.37165, saving model to /content/gdrive/My Drive/weights-improvement-20-1.3716-bigger.hdf5\n",
            "Epoch 21/100\n",
            "148335/148335 [==============================] - 123s 829us/step - loss: 1.3440\n",
            "\n",
            "Epoch 00021: loss improved from 1.37165 to 1.34398, saving model to /content/gdrive/My Drive/weights-improvement-21-1.3440-bigger.hdf5\n",
            "Epoch 22/100\n",
            "148335/148335 [==============================] - 122s 822us/step - loss: 1.3169\n",
            "\n",
            "Epoch 00022: loss improved from 1.34398 to 1.31689, saving model to /content/gdrive/My Drive/weights-improvement-22-1.3169-bigger.hdf5\n",
            "Epoch 23/100\n",
            "148335/148335 [==============================] - 121s 815us/step - loss: 1.2895\n",
            "\n",
            "Epoch 00023: loss improved from 1.31689 to 1.28953, saving model to /content/gdrive/My Drive/weights-improvement-23-1.2895-bigger.hdf5\n",
            "Epoch 24/100\n",
            "148335/148335 [==============================] - 121s 818us/step - loss: 1.2613\n",
            "\n",
            "Epoch 00024: loss improved from 1.28953 to 1.26130, saving model to /content/gdrive/My Drive/weights-improvement-24-1.2613-bigger.hdf5\n",
            "Epoch 25/100\n",
            "148335/148335 [==============================] - 120s 809us/step - loss: 1.2364\n",
            "\n",
            "Epoch 00025: loss improved from 1.26130 to 1.23643, saving model to /content/gdrive/My Drive/weights-improvement-25-1.2364-bigger.hdf5\n",
            "Epoch 26/100\n",
            "148335/148335 [==============================] - 120s 806us/step - loss: 1.2065\n",
            "\n",
            "Epoch 00026: loss improved from 1.23643 to 1.20654, saving model to /content/gdrive/My Drive/weights-improvement-26-1.2065-bigger.hdf5\n",
            "Epoch 27/100\n",
            "148335/148335 [==============================] - 120s 808us/step - loss: 1.1792\n",
            "\n",
            "Epoch 00027: loss improved from 1.20654 to 1.17920, saving model to /content/gdrive/My Drive/weights-improvement-27-1.1792-bigger.hdf5\n",
            "Epoch 28/100\n",
            "148335/148335 [==============================] - 119s 805us/step - loss: 1.1514\n",
            "\n",
            "Epoch 00028: loss improved from 1.17920 to 1.15143, saving model to /content/gdrive/My Drive/weights-improvement-28-1.1514-bigger.hdf5\n",
            "Epoch 29/100\n",
            "148335/148335 [==============================] - 120s 810us/step - loss: 1.1271\n",
            "\n",
            "Epoch 00029: loss improved from 1.15143 to 1.12707, saving model to /content/gdrive/My Drive/weights-improvement-29-1.1271-bigger.hdf5\n",
            "Epoch 30/100\n",
            "148335/148335 [==============================] - 119s 800us/step - loss: 1.1000\n",
            "\n",
            "Epoch 00030: loss improved from 1.12707 to 1.09998, saving model to /content/gdrive/My Drive/weights-improvement-30-1.1000-bigger.hdf5\n",
            "Epoch 31/100\n",
            "148335/148335 [==============================] - 119s 799us/step - loss: 1.0798\n",
            "\n",
            "Epoch 00031: loss improved from 1.09998 to 1.07976, saving model to /content/gdrive/My Drive/weights-improvement-31-1.0798-bigger.hdf5\n",
            "Epoch 32/100\n",
            "148335/148335 [==============================] - 119s 800us/step - loss: 1.0498\n",
            "\n",
            "Epoch 00032: loss improved from 1.07976 to 1.04984, saving model to /content/gdrive/My Drive/weights-improvement-32-1.0498-bigger.hdf5\n",
            "Epoch 33/100\n",
            "148335/148335 [==============================] - 118s 798us/step - loss: 1.0252\n",
            "\n",
            "Epoch 00033: loss improved from 1.04984 to 1.02516, saving model to /content/gdrive/My Drive/weights-improvement-33-1.0252-bigger.hdf5\n",
            "Epoch 34/100\n",
            "148335/148335 [==============================] - 119s 799us/step - loss: 1.0064\n",
            "\n",
            "Epoch 00034: loss improved from 1.02516 to 1.00637, saving model to /content/gdrive/My Drive/weights-improvement-34-1.0064-bigger.hdf5\n",
            "Epoch 35/100\n",
            "148335/148335 [==============================] - 120s 811us/step - loss: 0.9784\n",
            "\n",
            "Epoch 00035: loss improved from 1.00637 to 0.97843, saving model to /content/gdrive/My Drive/weights-improvement-35-0.9784-bigger.hdf5\n",
            "Epoch 36/100\n",
            "148335/148335 [==============================] - 120s 806us/step - loss: 0.9588\n",
            "\n",
            "Epoch 00036: loss improved from 0.97843 to 0.95878, saving model to /content/gdrive/My Drive/weights-improvement-36-0.9588-bigger.hdf5\n",
            "Epoch 37/100\n",
            "148335/148335 [==============================] - 120s 809us/step - loss: 0.9351\n",
            "\n",
            "Epoch 00037: loss improved from 0.95878 to 0.93513, saving model to /content/gdrive/My Drive/weights-improvement-37-0.9351-bigger.hdf5\n",
            "Epoch 38/100\n",
            "148335/148335 [==============================] - 119s 803us/step - loss: 0.9113\n",
            "\n",
            "Epoch 00038: loss improved from 0.93513 to 0.91126, saving model to /content/gdrive/My Drive/weights-improvement-38-0.9113-bigger.hdf5\n",
            "Epoch 39/100\n",
            "148335/148335 [==============================] - 119s 799us/step - loss: 0.8924\n",
            "\n",
            "Epoch 00039: loss improved from 0.91126 to 0.89244, saving model to /content/gdrive/My Drive/weights-improvement-39-0.8924-bigger.hdf5\n",
            "Epoch 40/100\n",
            "148335/148335 [==============================] - 119s 801us/step - loss: 0.8697\n",
            "\n",
            "Epoch 00040: loss improved from 0.89244 to 0.86967, saving model to /content/gdrive/My Drive/weights-improvement-40-0.8697-bigger.hdf5\n",
            "Epoch 41/100\n",
            "148335/148335 [==============================] - 119s 799us/step - loss: 0.8474\n",
            "\n",
            "Epoch 00041: loss improved from 0.86967 to 0.84737, saving model to /content/gdrive/My Drive/weights-improvement-41-0.8474-bigger.hdf5\n",
            "Epoch 42/100\n",
            "148335/148335 [==============================] - 119s 799us/step - loss: 0.8333\n",
            "\n",
            "Epoch 00042: loss improved from 0.84737 to 0.83331, saving model to /content/gdrive/My Drive/weights-improvement-42-0.8333-bigger.hdf5\n",
            "Epoch 43/100\n",
            "148335/148335 [==============================] - 118s 798us/step - loss: 0.8174\n",
            "\n",
            "Epoch 00043: loss improved from 0.83331 to 0.81738, saving model to /content/gdrive/My Drive/weights-improvement-43-0.8174-bigger.hdf5\n",
            "Epoch 44/100\n",
            "148335/148335 [==============================] - 118s 796us/step - loss: 0.7964\n",
            "\n",
            "Epoch 00044: loss improved from 0.81738 to 0.79641, saving model to /content/gdrive/My Drive/weights-improvement-44-0.7964-bigger.hdf5\n",
            "Epoch 45/100\n",
            "148335/148335 [==============================] - 119s 803us/step - loss: 0.7775\n",
            "\n",
            "Epoch 00045: loss improved from 0.79641 to 0.77748, saving model to /content/gdrive/My Drive/weights-improvement-45-0.7775-bigger.hdf5\n",
            "Epoch 46/100\n",
            "148335/148335 [==============================] - 119s 801us/step - loss: 0.7572\n",
            "\n",
            "Epoch 00046: loss improved from 0.77748 to 0.75716, saving model to /content/gdrive/My Drive/weights-improvement-46-0.7572-bigger.hdf5\n",
            "Epoch 47/100\n",
            "148335/148335 [==============================] - 118s 794us/step - loss: 0.7449\n",
            "\n",
            "Epoch 00047: loss improved from 0.75716 to 0.74490, saving model to /content/gdrive/My Drive/weights-improvement-47-0.7449-bigger.hdf5\n",
            "Epoch 48/100\n",
            "148335/148335 [==============================] - 118s 797us/step - loss: 0.7327\n",
            "\n",
            "Epoch 00048: loss improved from 0.74490 to 0.73274, saving model to /content/gdrive/My Drive/weights-improvement-48-0.7327-bigger.hdf5\n",
            "Epoch 49/100\n",
            "148335/148335 [==============================] - 118s 794us/step - loss: 0.7178\n",
            "\n",
            "Epoch 00049: loss improved from 0.73274 to 0.71780, saving model to /content/gdrive/My Drive/weights-improvement-49-0.7178-bigger.hdf5\n",
            "Epoch 50/100\n",
            "148335/148335 [==============================] - 118s 798us/step - loss: 0.7017\n",
            "\n",
            "Epoch 00050: loss improved from 0.71780 to 0.70172, saving model to /content/gdrive/My Drive/weights-improvement-50-0.7017-bigger.hdf5\n",
            "Epoch 51/100\n",
            "148335/148335 [==============================] - 118s 798us/step - loss: 0.6907\n",
            "\n",
            "Epoch 00051: loss improved from 0.70172 to 0.69075, saving model to /content/gdrive/My Drive/weights-improvement-51-0.6907-bigger.hdf5\n",
            "Epoch 52/100\n",
            "148335/148335 [==============================] - 117s 789us/step - loss: 0.6730\n",
            "\n",
            "Epoch 00052: loss improved from 0.69075 to 0.67296, saving model to /content/gdrive/My Drive/weights-improvement-52-0.6730-bigger.hdf5\n",
            "Epoch 53/100\n",
            "148335/148335 [==============================] - 119s 804us/step - loss: 0.6645\n",
            "\n",
            "Epoch 00053: loss improved from 0.67296 to 0.66453, saving model to /content/gdrive/My Drive/weights-improvement-53-0.6645-bigger.hdf5\n",
            "Epoch 54/100\n",
            "148335/148335 [==============================] - 118s 799us/step - loss: 0.6477\n",
            "\n",
            "Epoch 00054: loss improved from 0.66453 to 0.64770, saving model to /content/gdrive/My Drive/weights-improvement-54-0.6477-bigger.hdf5\n",
            "Epoch 55/100\n",
            "148335/148335 [==============================] - 118s 794us/step - loss: 0.6329\n",
            "\n",
            "Epoch 00055: loss improved from 0.64770 to 0.63294, saving model to /content/gdrive/My Drive/weights-improvement-55-0.6329-bigger.hdf5\n",
            "Epoch 56/100\n",
            "148335/148335 [==============================] - 118s 794us/step - loss: 0.6247\n",
            "\n",
            "Epoch 00056: loss improved from 0.63294 to 0.62473, saving model to /content/gdrive/My Drive/weights-improvement-56-0.6247-bigger.hdf5\n",
            "Epoch 57/100\n",
            "148335/148335 [==============================] - 117s 788us/step - loss: 0.6163\n",
            "\n",
            "Epoch 00057: loss improved from 0.62473 to 0.61627, saving model to /content/gdrive/My Drive/weights-improvement-57-0.6163-bigger.hdf5\n",
            "Epoch 58/100\n",
            "148335/148335 [==============================] - 118s 795us/step - loss: 0.6037\n",
            "\n",
            "Epoch 00058: loss improved from 0.61627 to 0.60369, saving model to /content/gdrive/My Drive/weights-improvement-58-0.6037-bigger.hdf5\n",
            "Epoch 59/100\n",
            "148335/148335 [==============================] - 117s 791us/step - loss: 0.5980\n",
            "\n",
            "Epoch 00059: loss improved from 0.60369 to 0.59801, saving model to /content/gdrive/My Drive/weights-improvement-59-0.5980-bigger.hdf5\n",
            "Epoch 60/100\n",
            "148335/148335 [==============================] - 116s 785us/step - loss: 0.5797\n",
            "\n",
            "Epoch 00060: loss improved from 0.59801 to 0.57969, saving model to /content/gdrive/My Drive/weights-improvement-60-0.5797-bigger.hdf5\n",
            "Epoch 61/100\n",
            "148335/148335 [==============================] - 118s 795us/step - loss: 0.5743\n",
            "\n",
            "Epoch 00061: loss improved from 0.57969 to 0.57426, saving model to /content/gdrive/My Drive/weights-improvement-61-0.5743-bigger.hdf5\n",
            "Epoch 62/100\n",
            "148335/148335 [==============================] - 118s 793us/step - loss: 0.5643\n",
            "\n",
            "Epoch 00062: loss improved from 0.57426 to 0.56426, saving model to /content/gdrive/My Drive/weights-improvement-62-0.5643-bigger.hdf5\n",
            "Epoch 63/100\n",
            "148335/148335 [==============================] - 117s 791us/step - loss: 0.5580\n",
            "\n",
            "Epoch 00063: loss improved from 0.56426 to 0.55797, saving model to /content/gdrive/My Drive/weights-improvement-63-0.5580-bigger.hdf5\n",
            "Epoch 64/100\n",
            "148335/148335 [==============================] - 117s 791us/step - loss: 0.5409\n",
            "\n",
            "Epoch 00064: loss improved from 0.55797 to 0.54091, saving model to /content/gdrive/My Drive/weights-improvement-64-0.5409-bigger.hdf5\n",
            "Epoch 65/100\n",
            "148335/148335 [==============================] - 118s 796us/step - loss: 0.5374\n",
            "\n",
            "Epoch 00065: loss improved from 0.54091 to 0.53740, saving model to /content/gdrive/My Drive/weights-improvement-65-0.5374-bigger.hdf5\n",
            "Epoch 66/100\n",
            "148335/148335 [==============================] - 119s 803us/step - loss: 0.5340\n",
            "\n",
            "Epoch 00066: loss improved from 0.53740 to 0.53397, saving model to /content/gdrive/My Drive/weights-improvement-66-0.5340-bigger.hdf5\n",
            "Epoch 67/100\n",
            "148335/148335 [==============================] - 119s 802us/step - loss: 0.5253\n",
            "\n",
            "Epoch 00067: loss improved from 0.53397 to 0.52533, saving model to /content/gdrive/My Drive/weights-improvement-67-0.5253-bigger.hdf5\n",
            "Epoch 68/100\n",
            "148335/148335 [==============================] - 119s 803us/step - loss: 0.5170\n",
            "\n",
            "Epoch 00068: loss improved from 0.52533 to 0.51703, saving model to /content/gdrive/My Drive/weights-improvement-68-0.5170-bigger.hdf5\n",
            "Epoch 69/100\n",
            "148335/148335 [==============================] - 120s 807us/step - loss: 0.5100\n",
            "\n",
            "Epoch 00069: loss improved from 0.51703 to 0.50999, saving model to /content/gdrive/My Drive/weights-improvement-69-0.5100-bigger.hdf5\n",
            "Epoch 70/100\n",
            "148335/148335 [==============================] - 119s 800us/step - loss: 0.5071\n",
            "\n",
            "Epoch 00070: loss improved from 0.50999 to 0.50709, saving model to /content/gdrive/My Drive/weights-improvement-70-0.5071-bigger.hdf5\n",
            "Epoch 71/100\n",
            "148335/148335 [==============================] - 119s 800us/step - loss: 0.5013\n",
            "\n",
            "Epoch 00071: loss improved from 0.50709 to 0.50131, saving model to /content/gdrive/My Drive/weights-improvement-71-0.5013-bigger.hdf5\n",
            "Epoch 72/100\n",
            "148335/148335 [==============================] - 118s 796us/step - loss: 0.4944\n",
            "\n",
            "Epoch 00072: loss improved from 0.50131 to 0.49443, saving model to /content/gdrive/My Drive/weights-improvement-72-0.4944-bigger.hdf5\n",
            "Epoch 73/100\n",
            "148335/148335 [==============================] - 117s 787us/step - loss: 0.4884\n",
            "\n",
            "Epoch 00073: loss improved from 0.49443 to 0.48840, saving model to /content/gdrive/My Drive/weights-improvement-73-0.4884-bigger.hdf5\n",
            "Epoch 74/100\n",
            "148335/148335 [==============================] - 117s 790us/step - loss: 0.4786\n",
            "\n",
            "Epoch 00074: loss improved from 0.48840 to 0.47863, saving model to /content/gdrive/My Drive/weights-improvement-74-0.4786-bigger.hdf5\n",
            "Epoch 75/100\n",
            "148335/148335 [==============================] - 117s 791us/step - loss: 0.4753\n",
            "\n",
            "Epoch 00075: loss improved from 0.47863 to 0.47532, saving model to /content/gdrive/My Drive/weights-improvement-75-0.4753-bigger.hdf5\n",
            "Epoch 76/100\n",
            "148335/148335 [==============================] - 117s 790us/step - loss: 0.4745\n",
            "\n",
            "Epoch 00076: loss improved from 0.47532 to 0.47453, saving model to /content/gdrive/My Drive/weights-improvement-76-0.4745-bigger.hdf5\n",
            "Epoch 77/100\n",
            "148335/148335 [==============================] - 117s 791us/step - loss: 0.4690\n",
            "\n",
            "Epoch 00077: loss improved from 0.47453 to 0.46904, saving model to /content/gdrive/My Drive/weights-improvement-77-0.4690-bigger.hdf5\n",
            "Epoch 78/100\n",
            "148335/148335 [==============================] - 117s 790us/step - loss: 0.4580\n",
            "\n",
            "Epoch 00078: loss improved from 0.46904 to 0.45802, saving model to /content/gdrive/My Drive/weights-improvement-78-0.4580-bigger.hdf5\n",
            "Epoch 79/100\n",
            "148335/148335 [==============================] - 117s 787us/step - loss: 0.4560\n",
            "\n",
            "Epoch 00079: loss improved from 0.45802 to 0.45604, saving model to /content/gdrive/My Drive/weights-improvement-79-0.4560-bigger.hdf5\n",
            "Epoch 80/100\n",
            "148335/148335 [==============================] - 116s 783us/step - loss: 0.4573\n",
            "\n",
            "Epoch 00080: loss did not improve from 0.45604\n",
            "Epoch 81/100\n",
            "148335/148335 [==============================] - 116s 783us/step - loss: 0.4521\n",
            "\n",
            "Epoch 00081: loss improved from 0.45604 to 0.45209, saving model to /content/gdrive/My Drive/weights-improvement-81-0.4521-bigger.hdf5\n",
            "Epoch 82/100\n",
            "148335/148335 [==============================] - 117s 786us/step - loss: 0.4334\n",
            "\n",
            "Epoch 00082: loss improved from 0.45209 to 0.43337, saving model to /content/gdrive/My Drive/weights-improvement-82-0.4334-bigger.hdf5\n",
            "Epoch 83/100\n",
            "148335/148335 [==============================] - 116s 780us/step - loss: 0.4427\n",
            "\n",
            "Epoch 00083: loss did not improve from 0.43337\n",
            "Epoch 84/100\n",
            "148335/148335 [==============================] - 116s 783us/step - loss: 0.4357\n",
            "\n",
            "Epoch 00084: loss did not improve from 0.43337\n",
            "Epoch 85/100\n",
            "148335/148335 [==============================] - 117s 787us/step - loss: 0.4351\n",
            "\n",
            "Epoch 00085: loss did not improve from 0.43337\n",
            "Epoch 86/100\n",
            "148335/148335 [==============================] - 117s 789us/step - loss: 0.4350\n",
            "\n",
            "Epoch 00086: loss did not improve from 0.43337\n",
            "Epoch 87/100\n",
            "148335/148335 [==============================] - 117s 788us/step - loss: 0.4350\n",
            "\n",
            "Epoch 00087: loss did not improve from 0.43337\n",
            "Epoch 88/100\n",
            "148335/148335 [==============================] - 116s 783us/step - loss: 0.4300\n",
            "\n",
            "Epoch 00088: loss improved from 0.43337 to 0.43000, saving model to /content/gdrive/My Drive/weights-improvement-88-0.4300-bigger.hdf5\n",
            "Epoch 89/100\n",
            "148335/148335 [==============================] - 116s 785us/step - loss: 0.4191\n",
            "\n",
            "Epoch 00089: loss improved from 0.43000 to 0.41910, saving model to /content/gdrive/My Drive/weights-improvement-89-0.4191-bigger.hdf5\n",
            "Epoch 90/100\n",
            "148335/148335 [==============================] - 118s 795us/step - loss: 0.4147\n",
            "\n",
            "Epoch 00090: loss improved from 0.41910 to 0.41468, saving model to /content/gdrive/My Drive/weights-improvement-90-0.4147-bigger.hdf5\n",
            "Epoch 91/100\n",
            "148335/148335 [==============================] - 117s 791us/step - loss: 0.4188\n",
            "\n",
            "Epoch 00091: loss did not improve from 0.41468\n",
            "Epoch 92/100\n",
            "148335/148335 [==============================] - 117s 790us/step - loss: 0.4156\n",
            "\n",
            "Epoch 00092: loss did not improve from 0.41468\n",
            "Epoch 93/100\n",
            "148335/148335 [==============================] - 116s 783us/step - loss: 0.4150\n",
            "\n",
            "Epoch 00093: loss did not improve from 0.41468\n",
            "Epoch 94/100\n",
            "148335/148335 [==============================] - 115s 772us/step - loss: 0.4081\n",
            "\n",
            "Epoch 00094: loss improved from 0.41468 to 0.40809, saving model to /content/gdrive/My Drive/weights-improvement-94-0.4081-bigger.hdf5\n",
            "Epoch 95/100\n",
            "148335/148335 [==============================] - 115s 777us/step - loss: 0.4059\n",
            "\n",
            "Epoch 00095: loss improved from 0.40809 to 0.40592, saving model to /content/gdrive/My Drive/weights-improvement-95-0.4059-bigger.hdf5\n",
            "Epoch 96/100\n",
            "148335/148335 [==============================] - 116s 783us/step - loss: 0.3959\n",
            "\n",
            "Epoch 00096: loss improved from 0.40592 to 0.39586, saving model to /content/gdrive/My Drive/weights-improvement-96-0.3959-bigger.hdf5\n",
            "Epoch 97/100\n",
            "148335/148335 [==============================] - 115s 775us/step - loss: 0.4046\n",
            "\n",
            "Epoch 00097: loss did not improve from 0.39586\n",
            "Epoch 98/100\n",
            "148335/148335 [==============================] - 115s 778us/step - loss: 0.3945\n",
            "\n",
            "Epoch 00098: loss improved from 0.39586 to 0.39454, saving model to /content/gdrive/My Drive/weights-improvement-98-0.3945-bigger.hdf5\n",
            "Epoch 99/100\n",
            "148335/148335 [==============================] - 116s 780us/step - loss: 0.3930\n",
            "\n",
            "Epoch 00099: loss improved from 0.39454 to 0.39296, saving model to /content/gdrive/My Drive/weights-improvement-99-0.3930-bigger.hdf5\n",
            "Epoch 100/100\n",
            "148335/148335 [==============================] - 116s 781us/step - loss: 0.3901\n",
            "\n",
            "Epoch 00100: loss improved from 0.39296 to 0.39013, saving model to /content/gdrive/My Drive/weights-improvement-100-0.3901-bigger.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f955679ccc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ej8WJ6XsVfaf",
        "colab_type": "text"
      },
      "source": [
        "#Loading the best weights for prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGaacJcNOFpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the network weights\n",
        "filename = \"/content/gdrive/My Drive/weights-improvement-100-0.3901-bigger.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lppppj5KVXHA",
        "colab_type": "text"
      },
      "source": [
        "#Predicting the next 500 characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEogWyiNOGSM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "e08f11d7-7b86-4eaf-86a9-d79864c8a112"
      },
      "source": [
        "# pick a random seed\n",
        "start = np.random.randint(0, len(dataX)-1)\n",
        "pattern = list(dataX[start])\n",
        "print (\"Seed:\")\n",
        "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "\" \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "assistance they need is critical t \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KUoPkLJNy60",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "27a6708d-2bd0-44ea-95e1-04f4cd02c9ef"
      },
      "source": [
        "# generate characters\n",
        "for i in range(500):\n",
        "\tx = np.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = np.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print (\"\\nDone.\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "eperbired all tvouf and sle fown onke ovngr iittelt pear thfe asd wherks ookeny sererked ofttele bnlce whed whats bfoune bnlcedd whed whats tuomoningd tuier toatdt whan harpinatce sfpple bnlce when tolan moke tuanfcost iordh ang kov fanlilt uoek toealnlg tuuftcer sf larpensy wrnes tf ltcssed iom bnice dvoed thf atkidgddle dogr trecling the atoee tous allrg tuinilid tvittiotat trining b mittle bni iet hace onke tuofesfy oedg harrtw su musely asd hopctretexlog or foectccss o wegd iu tocadle ior cr\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}