{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2A-B.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDoobERk8Cci",
        "colab_type": "text"
      },
      "source": [
        "## Name: Soma Korada\n",
        "## Email: somakorada@gmail.com\n",
        "## Batch: 5\n",
        "\n",
        "# 2A Assignment\n",
        "\n",
        "Consider a neural network with three layers:\n",
        "1.   Input layer with two inputs neurons\n",
        "2.   One hidden layer with two neurons\n",
        "3.   Output layer with a single neuron\n",
        "\n",
        "\n",
        "![alt text](http://hmkcode.github.io/images/ai/nn1.png)\n",
        "\n",
        "Let initial weights be as following: w1 = 0.13, w2 = 0.22, w3 = 0.11, w4 = 0.09, w5 = 0.16 and w6 = 0.18\n",
        "\n",
        "![alt text](https://github.com/SomaKorada07/EIP/blob/master/bp_weights.png?raw=true)\n",
        "\n",
        "\n",
        "Consider dataset with two inputs and one output.\n",
        "\n",
        "![alt text](http://hmkcode.github.io/images/ai/bp_dataset.png)\n",
        "\n",
        "\n",
        "Our single sample is as following inputs=[2, 3] and output=[1]\n",
        "\n",
        "![alt text](http://hmkcode.github.io/images/ai/bp_sample.png)\n",
        "\n",
        "\n",
        "# Forward Pass\n",
        "The inputs are multiplied with the new weights and the results are passed to the next layer.\n",
        "\n",
        "![alt text](https://github.com/SomaKorada07/EIP/blob/master/bp_forward.png?raw=true)\n",
        "\n",
        "# Calculating Error\n",
        "We can check the performance of the network by calculating the error. In our case, prediction is not close to the actual output meaning there is huge error.\n",
        "\n",
        "![alt text](https://github.com/SomaKorada07/EIP/blob/master/bp_error.png?raw=true)\n",
        "\n",
        "# Reducing Error\n",
        "We need to reduce the error, i.e. difference between the prediction and actual output. As actual output is constant, we need to reduce the prediction.\n",
        "\n",
        "As input values are constant, we need to change the weights in order to change the prediction.\n",
        "\n",
        "![alt text](http://hmkcode.github.io/images/ai/bp_prediction_elements.png)\n",
        "\n",
        "# Backpropagation\n",
        "Backpropagation uses Gradient Descent concept to change the weights. It calculates the gradient of the error with respect to the weights.\n",
        "\n",
        "![alt text](http://hmkcode.github.io/images/ai/bp_update_formula.png)\n",
        "\n",
        "For example, to update w6, we take the current w6 and subtract the partial derivative of error function with respect to w6. Optionally, we multiply the derivative of the error function by a selected number to make sure that the new updated weight is minimizing the error function; this number is called learning rate.\n",
        "\n",
        "![alt text](http://hmkcode.github.io/images/ai/bp_w6_update.png)\n",
        "\n",
        "The derivation of the error function is evaluated by applying the chain rule as following\n",
        "\n",
        "![alt text](http://hmkcode.github.io/images/ai/bp_error_function_partial_derivative_w6.png)\n",
        "\n",
        "Hence the following\n",
        "\n",
        "![alt text](http://hmkcode.github.io/images/ai/bp_w6_update_closed_form.png)\n",
        "\n",
        "![alt text](http://hmkcode.github.io/images/ai/bp_w5_update_closed_form.png)\n",
        "\n",
        "When moving backward to update w1, w2, w3 and w4 existing between input and hidden layer, the partial derivative for the error function with respect to w1, for example, will be as following:\n",
        "\n",
        "![alt text](http://hmkcode.github.io/images/ai/bp_error_function_partial_derivative_w1.png)\n",
        "\n",
        "In summary, the update formulas for all weights will be as following:\n",
        "\n",
        "![alt text](http://hmkcode.github.io/images/ai/bp_update_all_weights.png)\n",
        "\n",
        "We can rewrite the update formulas in matrices as following:\n",
        "\n",
        "![alt text](http://hmkcode.github.io/images/ai/bp_update_all_weights_matrix.png)\n",
        "\n",
        "![alt text](http://hmkcode.github.io/images/ai/bp_update_all_weights_matrix.png)\n",
        "\n",
        "\n",
        "# Backward Pass\n",
        "Using the above formulae, new weights can be calculated as\n",
        "\n",
        "![alt text](https://github.com/SomaKorada07/EIP/blob/master/bp_new_weights.png?raw=true)\n",
        "\n",
        "Now, using the new weights we will repeat the forward pass.\n",
        "\n",
        "![alt text](https://github.com/SomaKorada07/EIP/blob/master/bp_forward_2.png?raw=true)\n",
        "\n",
        "The new prediction 0.28 is a little bit closer to actual output than the previously predicted one 0.235. We can repeat the same process of backward and forward pass until error is close or equal to zero.\n",
        "\n",
        "\n",
        "# 2B Assignment\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhQ_U9Q2YXq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#forward pass with weights w1=.13,w2=.22,w3=.11,w4=.09,w5=.16,w6=.18\n",
        "import numpy as np\n",
        "input_array=np.array([[2,3]])\n",
        "weights = np.array([[0.13,.11],[.22,.09]])\n",
        "hidden_activation=np.dot(input_array,weights)\n",
        "second_weights=np.array([[0.16],[0.18]])\n",
        "out=np.dot(hidden_activation,second_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1VdYUbmbQfM",
        "colab_type": "code",
        "outputId": "4a6fdb96-ea26-45a4-d141-b07d119fc5b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "out"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.2354]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REiDUBHYbT8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Calculating the error\n",
        "actual = 1\n",
        "error=(1/2)*(out[0][0]-actual)**2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxoLKFGrXLO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Assuming the learning rate as 0.05, find the delta\n",
        "learning_rate = 0.05\n",
        "delta = out[0][0] - actual\n",
        "factor = learning_rate * delta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIhK-iEEYr3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#finding the better weights to further reduce the error \n",
        "new_second_weights = second_weights -(np.transpose(hidden_activation)*factor)\n",
        "new_weights = weights - (np.dot(np.transpose(input_array)*factor,np.transpose(second_weights)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgI2gBMRYst6",
        "colab_type": "code",
        "outputId": "4fada46c-91fe-49af-aec1-b3aaccf35ecb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "new_second_weights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.1951716],\n",
              "       [0.1987327]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7muOtfG5ZtHt",
        "colab_type": "code",
        "outputId": "f945b04a-9e06-4439-e770-7ea5845ed772",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "new_weights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.1422336, 0.1237628],\n",
              "       [0.2383504, 0.1106442]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxsm2Z_GZ0O8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Performing forward pass with the new weights - finding new output\n",
        "new_weight_hidden = np.dot(input_array,new_weights)\n",
        "new_output = np.dot(new_weight_hidden,new_second_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJvg_OUjaMzQ",
        "colab_type": "code",
        "outputId": "27bba085-d7d6-4b6e-9528-7a531869d367",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "new_output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.3102349]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}